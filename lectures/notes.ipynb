{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo integration\n",
    "\n",
    "You might have seen this already, but Monte Carlo integration is an absolute crucial notion in modern statistics (modern because it relies on generating a large number of data points, which has been made possible by computers). Suppose you have very a complicated integral to solve and that you can write down the integrand as a product of $f(x)$ and $p(x)$ with $\\int p(x)=1$ (this is not restrictive at all! See below). My nasty integral is\n",
    "\n",
    "$$\\int f(x) p(x) dx$$\n",
    "\n",
    "\n",
    "Provided one can **evaluate** $f(x)$ and **sample** $p(x)$, then\n",
    "\n",
    "\n",
    "$$\\int f(x) p(x) dx \\approx \\frac{1}{N}\\sum_{i=1}^N f(x_i) $$\n",
    "\n",
    "where $x_i$ are samples drawn from $p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics:\n",
    "- location\n",
    "- scale\n",
    "- shape\n",
    "\n",
    "\n",
    "#### **location**\n",
    "mean: actually comes from Monte Carlo integration to get the fist moment of the distribution\n",
    "$$\\mu = E(x) = \\langle x \\rangle = \\int_{-\\infty}^{\\infty} x h(x)\\,dx \\approx \\frac{1}{N}\\sum_{i=1}^N x_i $$\n",
    "\n",
    "median --> more robust estimator of the true location of the distribution --> less affected by outliers  since  **cumulative statistics based on the ordering of samples would remain unaffected by the outlier corruption**.\n",
    "\n",
    "#### **scale**\n",
    "\n",
    "\n",
    "#### **shape**\n",
    "deviations from average $$d_i = x_i - \\mu $$\n",
    "MAD (mean abl√¨solute devaition) : $$\\frac{1}{N}\\sum|x_i-\\mu|,$$\n",
    "variance  $$ \\sigma ^2 = \\frac{1}{N}\\sum(x_i-\\mu)^2 $$\n",
    "\n",
    "$$\\sigma^2 = V = E((x-\\mu)^2)\\int_{-\\infty}^{\\infty}  (x-\\mu)^2 h(x) dx $$\n",
    "\n",
    "\n",
    "quantiles etc ...$$\\sigma_G $$\n",
    "\n",
    "Other useful ***shape*** measures include the \"higher order\" moments (the **skewness** and **kurtosis**):\n",
    "\n",
    "$$\\mathbf{Skewness}\\quad\\quad \\Sigma = \\int_{-\\infty}^{\\infty}  \\left(\\frac{x-\\mu}{\\sigma}\\right)^3 h(x) dx,$$\n",
    " \n",
    "$$\\mathbf{Kurtosis}\\quad\\quad K = \\int_{-\\infty}^{\\infty}  \\left(\\frac{x-\\mu}{\\sigma}\\right)^4 h(x) dx  - 3.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample versus Population statistics <a class=\"anchor\" id=\"two\"></a>\n",
    "\n",
    "Statistics estimated from the *data* are called **sample statistics** as compared to **population statistics** derived from knowing the functional form of the pdf.\n",
    "\n",
    "Specifically, $\\mu$ is the **population mean**, i.e., it is the expectation value of $x$ for $h(x)$.  But we don't *know* $h(x)$.  So the **sample mean**, $\\overline{x}$, is an ***estimator*** of $\\mu$, defined as\n",
    "\n",
    "$$\\overline{x} \\equiv \\frac{1}{N}\\sum_{i=1}^N x_i,$$\n",
    "\n",
    "which we determine from the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
