{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acd125e-8ade-4fcb-b6c2-aa5e392b0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install --upgrade pip\n",
    " #!pip3 install tensorflow\n",
    " #!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c8a8e",
   "metadata": {},
   "source": [
    "## Time to get your hands dirty. Galaxies vs quasars with neural networks.\n",
    "\n",
    "Let's go back to our galaxy vs quasar data we've used in a previous exercise. \n",
    "\n",
    "1. Read in SDSS galaxy color data from `solutions/galaxyquasar.csv`. Create arrays for the $(u-g)$, $(g-r)$, $(r-i)$, and $(i-z)$ colors. Also create an array with the class labels where galaxy=$0$ and quasar=$1$. \n",
    "\n",
    "2. Now we're going to fit a neural network classifier. First, scale your data appropriately and do a 30% train/test split.\n",
    "\n",
    "3. Now train the classifier. Use one the package among those we've seen. These include Tensorflow via keras, pytorch, and the MPL classifier implemented in scikit-learn. This is an opportunity to pick the one you're most interested in learning. \n",
    "\n",
    "3. Start from a network architecture with a single hidden layer with 5 neurons, using the `adam` solver, the `relu` activation function, and a learninig rate of `0.001`. Plot the resulting ROC curve. \n",
    "\n",
    "4. Now let's optimize the hyperparameters of your network. Explore different hyperparameters and see what fits the data best.  Do your best now to optimize the network architecture. Be creative!\n",
    "\n",
    "5. Is your best result comparable with the simpler classifiers we've seen before? Do we need deep learning here? If yes, which features are captured best?\n",
    "\n",
    "\n",
    "A few tips:\n",
    "\n",
    "- In scikit-learn, remember that you can utilize all availables cores on your machine with `n_jobs=-1`. Print out the classification score for the training data, and the best parameters obtained by the cross validation.\n",
    "- If it takes too long, run the hyperparameter optimization on a subset of the training set. Then retrain the full network using the best hyperparameters only.\n",
    "- On cross validation, for scikit learn we've seen how to use `GridSearchCV` already. For Tensorflow, there's a really cool tool called [Tensorboard](https://www.tensorflow.org/tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d52f09d-8cbf-4de9-871b-e7b18e458930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setuptools.dist\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import deepdish\n",
    "\n",
    "#import  torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea5362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('../solutions/galaxyquasar.csv')\n",
    "\n",
    "u_g = data['u'] - data['g']\n",
    "g_r = data['g'] - data['r']\n",
    "r_i = data['r'] - data['i']\n",
    "i_z = data['i'] - data['z']\n",
    "\n",
    "labels = data['class'].apply(lambda x: 0 if x == 'GALAXY' else 1)\n",
    "\n",
    "features = pd.DataFrame({'u-g': u_g, 'g-r': g_r, 'r-i': r_i, 'i-z': i_z})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebc47d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "      <th>z1</th>\n",
       "      <th>zerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.97213</td>\n",
       "      <td>18.53676</td>\n",
       "      <td>18.58280</td>\n",
       "      <td>18.34936</td>\n",
       "      <td>18.29215</td>\n",
       "      <td>QSO</td>\n",
       "      <td>0.522819</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.24592</td>\n",
       "      <td>17.47646</td>\n",
       "      <td>16.47817</td>\n",
       "      <td>16.04472</td>\n",
       "      <td>15.68851</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.122846</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.43536</td>\n",
       "      <td>17.70268</td>\n",
       "      <td>16.91565</td>\n",
       "      <td>16.58327</td>\n",
       "      <td>16.39128</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.31626</td>\n",
       "      <td>18.18312</td>\n",
       "      <td>17.39591</td>\n",
       "      <td>16.94549</td>\n",
       "      <td>16.65395</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.147435</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.28828</td>\n",
       "      <td>19.11188</td>\n",
       "      <td>18.88937</td>\n",
       "      <td>18.80013</td>\n",
       "      <td>18.49183</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2.011455</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>19.37295</td>\n",
       "      <td>18.12382</td>\n",
       "      <td>17.39886</td>\n",
       "      <td>16.98503</td>\n",
       "      <td>16.70585</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.113016</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>18.52021</td>\n",
       "      <td>16.88262</td>\n",
       "      <td>16.03280</td>\n",
       "      <td>15.56884</td>\n",
       "      <td>15.22454</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.085063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>18.62718</td>\n",
       "      <td>17.30876</td>\n",
       "      <td>16.87371</td>\n",
       "      <td>16.62399</td>\n",
       "      <td>16.42296</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.054429</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>19.55140</td>\n",
       "      <td>18.27711</td>\n",
       "      <td>17.62101</td>\n",
       "      <td>17.21947</td>\n",
       "      <td>17.03347</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.112571</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>18.80772</td>\n",
       "      <td>17.75751</td>\n",
       "      <td>17.40500</td>\n",
       "      <td>17.21650</td>\n",
       "      <td>17.12295</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              u         g         r         i         z   class        z1  \\\n",
       "0      18.97213  18.53676  18.58280  18.34936  18.29215     QSO  0.522819   \n",
       "1      19.24592  17.47646  16.47817  16.04472  15.68851  GALAXY  0.122846   \n",
       "2      19.43536  17.70268  16.91565  16.58327  16.39128  GALAXY  0.000000   \n",
       "3      19.31626  18.18312  17.39591  16.94549  16.65395  GALAXY  0.147435   \n",
       "4      19.28828  19.11188  18.88937  18.80013  18.49183     QSO  2.011455   \n",
       "...         ...       ...       ...       ...       ...     ...       ...   \n",
       "49995  19.37295  18.12382  17.39886  16.98503  16.70585  GALAXY  0.113016   \n",
       "49996  18.52021  16.88262  16.03280  15.56884  15.22454  GALAXY  0.085063   \n",
       "49997  18.62718  17.30876  16.87371  16.62399  16.42296  GALAXY  0.054429   \n",
       "49998  19.55140  18.27711  17.62101  17.21947  17.03347  GALAXY  0.112571   \n",
       "49999  18.80772  17.75751  17.40500  17.21650  17.12295  GALAXY  0.043652   \n",
       "\n",
       "           zerr  \n",
       "0      0.000155  \n",
       "1      0.000028  \n",
       "2      0.000000  \n",
       "3      0.000009  \n",
       "4      0.000631  \n",
       "...         ...  \n",
       "49995  0.000011  \n",
       "49996  0.000014  \n",
       "49997  0.000008  \n",
       "49998  0.000009  \n",
       "49999  0.000007  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0895402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's scale them\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3ccbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9348161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malvi/venv/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.3455 - val_accuracy: 0.9824 - val_loss: 0.0847 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0892 - val_accuracy: 0.9820 - val_loss: 0.0773 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0766 - val_accuracy: 0.9819 - val_loss: 0.0755 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0725 - val_accuracy: 0.9819 - val_loss: 0.0757 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0788 - val_accuracy: 0.9832 - val_loss: 0.0746 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0834 - val_accuracy: 0.9833 - val_loss: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0718 - val_accuracy: 0.9824 - val_loss: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0747 - val_accuracy: 0.9824 - val_loss: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0738 - val_accuracy: 0.9825 - val_loss: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0797 - val_accuracy: 0.9832 - val_loss: 0.0742 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0747 - val_accuracy: 0.9832 - val_loss: 0.0743 - learning_rate: 9.5123e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0739 - val_accuracy: 0.9819 - val_loss: 0.0749 - learning_rate: 9.0484e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0745 - val_accuracy: 0.9827 - val_loss: 0.0744 - learning_rate: 8.6071e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0768 - val_accuracy: 0.9824 - val_loss: 0.0742 - learning_rate: 8.1873e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0729 - val_accuracy: 0.9832 - val_loss: 0.0739 - learning_rate: 7.7880e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0727 - val_accuracy: 0.9832 - val_loss: 0.0743 - learning_rate: 7.4082e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0695 - val_accuracy: 0.9829 - val_loss: 0.0743 - learning_rate: 7.0469e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0740 - val_accuracy: 0.9832 - val_loss: 0.0740 - learning_rate: 6.7032e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0737 - val_accuracy: 0.9837 - val_loss: 0.0734 - learning_rate: 6.3763e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0745 - val_accuracy: 0.9825 - val_loss: 0.0740 - learning_rate: 6.0653e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0730 - val_accuracy: 0.9833 - val_loss: 0.0737 - learning_rate: 5.7695e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0718 - val_accuracy: 0.9835 - val_loss: 0.0735 - learning_rate: 5.4881e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0703 - val_accuracy: 0.9837 - val_loss: 0.0734 - learning_rate: 5.2205e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0768 - val_accuracy: 0.9837 - val_loss: 0.0734 - learning_rate: 4.9659e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0718 - val_accuracy: 0.9836 - val_loss: 0.0733 - learning_rate: 4.7237e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0742 - val_accuracy: 0.9836 - val_loss: 0.0732 - learning_rate: 4.4933e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0735 - val_accuracy: 0.9827 - val_loss: 0.0736 - learning_rate: 4.2742e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0817 - val_accuracy: 0.9837 - val_loss: 0.0731 - learning_rate: 4.0657e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0721 - val_accuracy: 0.9836 - val_loss: 0.0729 - learning_rate: 3.8674e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0706 - val_accuracy: 0.9837 - val_loss: 0.0729 - learning_rate: 3.6788e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0752 - val_accuracy: 0.9836 - val_loss: 0.0730 - learning_rate: 3.4994e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0737 - val_accuracy: 0.9837 - val_loss: 0.0731 - learning_rate: 3.3287e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0717 - val_accuracy: 0.9837 - val_loss: 0.0733 - learning_rate: 3.1664e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0725 - val_accuracy: 0.9836 - val_loss: 0.0728 - learning_rate: 3.0119e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0699 - val_accuracy: 0.9837 - val_loss: 0.0731 - learning_rate: 2.8651e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0721 - val_accuracy: 0.9836 - val_loss: 0.0727 - learning_rate: 2.7253e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0723 - val_accuracy: 0.9834 - val_loss: 0.0726 - learning_rate: 2.5924e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0683 - val_accuracy: 0.9837 - val_loss: 0.0726 - learning_rate: 2.4660e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0712 - val_accuracy: 0.9836 - val_loss: 0.0726 - learning_rate: 2.3457e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0716 - val_accuracy: 0.9839 - val_loss: 0.0725 - learning_rate: 2.2313e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0719 - val_accuracy: 0.9835 - val_loss: 0.0724 - learning_rate: 2.1225e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0680 - val_accuracy: 0.9837 - val_loss: 0.0724 - learning_rate: 2.0190e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0659 - val_accuracy: 0.9837 - val_loss: 0.0723 - learning_rate: 1.9205e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0722 - val_accuracy: 0.9837 - val_loss: 0.0723 - learning_rate: 1.8268e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0738 - val_accuracy: 0.9837 - val_loss: 0.0723 - learning_rate: 1.7377e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0709 - val_accuracy: 0.9838 - val_loss: 0.0722 - learning_rate: 1.6530e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0676 - val_accuracy: 0.9838 - val_loss: 0.0722 - learning_rate: 1.5724e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0695 - val_accuracy: 0.9839 - val_loss: 0.0721 - learning_rate: 1.4957e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0715 - val_accuracy: 0.9839 - val_loss: 0.0721 - learning_rate: 1.4227e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m3500/3500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0660 - val_accuracy: 0.9838 - val_loss: 0.0721 - learning_rate: 1.3534e-04\n"
     ]
    }
   ],
   "source": [
    "filename='trained.keras'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "        \n",
    "    my_init = keras.initializers.glorot_uniform(seed=1)\n",
    "    model = keras.Sequential( [\n",
    "                # Input layer, do not change\n",
    "                tf.keras.layers.InputLayer(input_shape=np.shape(X_train[0])),\n",
    "                # Inner layers, can add/change\n",
    "                keras.layers.Dense(5,  activation='relu',kernel_initializer=my_init),\n",
    "                #keras.layers.Dense(16,  activation='tanh',kernel_initializer=my_init),\n",
    "                #keras.layers.Dense(8,  activation='tanh',kernel_initializer=my_init),\n",
    "                # Output layer, do not change\n",
    "                keras.layers.Dense(1, activation='sigmoid',kernel_initializer=my_init)])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "                if epoch < 10:\n",
    "                    return float(lr)\n",
    "                else:\n",
    "                    return float(lr * tf.math.exp(-0.05))\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=50, batch_size=10, validation_data=(X_test, y_test),\n",
    "                        callbacks = [\n",
    "                            # Drecrease learning rate\n",
    "                            tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "                            # Store the model with the best validation accuracy\n",
    "                            tf.keras.callbacks.ModelCheckpoint(\n",
    "                                filepath=filename,\n",
    "                                save_weights_only=False,\n",
    "                                monitor='val_accuracy',\n",
    "                                mode='max',\n",
    "                                save_best_only=True),\n",
    "                            # Save logfiles for tensorboard\n",
    "                            tf.keras.callbacks.TensorBoard(log_dir=\"logs\"+filename.split('.h5')[0], histogram_freq=1)],\n",
    "                        \n",
    "                        # Shuffle data at each epoch\n",
    "                        shuffle=True)\n",
    "\n",
    "    # Load the best model\n",
    "    model = keras.models.load_model(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76a55837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "y_pred_prob = model.predict(X_test).ravel()  #(ravel flattens the array), can also use squeeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b4de2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"my_keras_model.keras\")\n",
    "\n",
    "# Reload model\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "465c3459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='teal', lw=2, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6eeb4901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9827 - loss: 0.0771\n",
      "Classification score:  0.9839333295822144\n"
     ]
    }
   ],
   "source": [
    "# print the classification score:\n",
    "\n",
    "print('Classification score: ', model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f40254",
   "metadata": {},
   "source": [
    "## Let's now find the best hyperparameters for the network, cross validation with Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "990ab5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 25s]\n",
      "val_accuracy: 0.9843999743461609\n",
      "\n",
      "Best val_accuracy So Far: 0.9850666522979736\n",
      "Total elapsed time: 00h 05m 56s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 15 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=np.shape(X_train[0])))\n",
    "    \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units = hp.Int('units', min_value=5, max_value=50, step=5)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu', kernel_initializer=my_init))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid', kernel_initializer=my_init))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[stop_early, tf.keras.callbacks.TensorBoard(log_dir=\"logs/hparam_tuning\")])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fb1c8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 15 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Import TensorBoard\n",
    "\n",
    "# Define the log directory\n",
    "log_dir = \"logs/hparam_tuning\"\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Use the TensorBoard callback in the tuner search\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[stop_early, tensorboard_callback])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde918d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a2c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e4dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
