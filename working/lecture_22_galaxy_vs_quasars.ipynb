{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acd125e-8ade-4fcb-b6c2-aa5e392b0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install --upgrade pip\n",
    " #!pip3 install tensorflow\n",
    " #!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c8a8e",
   "metadata": {},
   "source": [
    "## Time to get your hands dirty. Galaxies vs quasars with neural networks.\n",
    "\n",
    "Let's go back to our galaxy vs quasar data we've used in a previous exercise. \n",
    "\n",
    "1. Read in SDSS galaxy color data from `solutions/galaxyquasar.csv`. Create arrays for the $(u-g)$, $(g-r)$, $(r-i)$, and $(i-z)$ colors. Also create an array with the class labels where galaxy=$0$ and quasar=$1$. \n",
    "\n",
    "2. Now we're going to fit a neural network classifier. First, scale your data appropriately and do a 30% train/test split.\n",
    "\n",
    "3. Now train the classifier. Use one the package among those we've seen. These include Tensorflow via keras, pytorch, and the MPL classifier implemented in scikit-learn. This is an opportunity to pick the one you're most interested in learning. \n",
    "\n",
    "3. Start from a network architecture with a single hidden layer with 5 neurons, using the `adam` solver, the `relu` activation function, and a learninig rate of `0.001`. Plot the resulting ROC curve. \n",
    "\n",
    "4. Now let's optimize the hyperparameters of your network. Explore different hyperparameters and see what fits the data best.  Do your best now to optimize the network architecture. Be creative!\n",
    "\n",
    "5. Is your best result comparable with the simpler classifiers we've seen before? Do we need deep learning here? If yes, which features are captured best?\n",
    "\n",
    "\n",
    "A few tips:\n",
    "\n",
    "- In scikit-learn, remember that you can utilize all availables cores on your machine with `n_jobs=-1`. Print out the classification score for the training data, and the best parameters obtained by the cross validation.\n",
    "- If it takes too long, run the hyperparameter optimization on a subset of the training set. Then retrain the full network using the best hyperparameters only.\n",
    "- On cross validation, for scikit learn we've seen how to use `GridSearchCV` already. For Tensorflow, there's a really cool tool called [Tensorboard](https://www.tensorflow.org/tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d52f09d-8cbf-4de9-871b-e7b18e458930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 00:38:33.608872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-25 00:38:33.691491: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-25 00:38:33.716311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-25 00:38:33.869475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 00:38:35.869234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import setuptools.dist\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import deepdish\n",
    "\n",
    "#import  torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea5362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('../solutions/galaxyquasar.csv')\n",
    "\n",
    "u_g = data['u'] - data['g']\n",
    "g_r = data['g'] - data['r']\n",
    "r_i = data['r'] - data['i']\n",
    "i_z = data['i'] - data['z']\n",
    "\n",
    "labels = data['class'].apply(lambda x: 0 if x == 'GALAXY' else 1)\n",
    "\n",
    "features = pd.DataFrame({'u-g': u_g, 'g-r': g_r, 'r-i': r_i, 'i-z': i_z})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc47d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "      <th>z1</th>\n",
       "      <th>zerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.97213</td>\n",
       "      <td>18.53676</td>\n",
       "      <td>18.58280</td>\n",
       "      <td>18.34936</td>\n",
       "      <td>18.29215</td>\n",
       "      <td>QSO</td>\n",
       "      <td>0.522819</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.24592</td>\n",
       "      <td>17.47646</td>\n",
       "      <td>16.47817</td>\n",
       "      <td>16.04472</td>\n",
       "      <td>15.68851</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.122846</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.43536</td>\n",
       "      <td>17.70268</td>\n",
       "      <td>16.91565</td>\n",
       "      <td>16.58327</td>\n",
       "      <td>16.39128</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.31626</td>\n",
       "      <td>18.18312</td>\n",
       "      <td>17.39591</td>\n",
       "      <td>16.94549</td>\n",
       "      <td>16.65395</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.147435</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.28828</td>\n",
       "      <td>19.11188</td>\n",
       "      <td>18.88937</td>\n",
       "      <td>18.80013</td>\n",
       "      <td>18.49183</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2.011455</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>19.37295</td>\n",
       "      <td>18.12382</td>\n",
       "      <td>17.39886</td>\n",
       "      <td>16.98503</td>\n",
       "      <td>16.70585</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.113016</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>18.52021</td>\n",
       "      <td>16.88262</td>\n",
       "      <td>16.03280</td>\n",
       "      <td>15.56884</td>\n",
       "      <td>15.22454</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.085063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>18.62718</td>\n",
       "      <td>17.30876</td>\n",
       "      <td>16.87371</td>\n",
       "      <td>16.62399</td>\n",
       "      <td>16.42296</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.054429</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>19.55140</td>\n",
       "      <td>18.27711</td>\n",
       "      <td>17.62101</td>\n",
       "      <td>17.21947</td>\n",
       "      <td>17.03347</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.112571</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>18.80772</td>\n",
       "      <td>17.75751</td>\n",
       "      <td>17.40500</td>\n",
       "      <td>17.21650</td>\n",
       "      <td>17.12295</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              u         g         r         i         z   class        z1  \\\n",
       "0      18.97213  18.53676  18.58280  18.34936  18.29215     QSO  0.522819   \n",
       "1      19.24592  17.47646  16.47817  16.04472  15.68851  GALAXY  0.122846   \n",
       "2      19.43536  17.70268  16.91565  16.58327  16.39128  GALAXY  0.000000   \n",
       "3      19.31626  18.18312  17.39591  16.94549  16.65395  GALAXY  0.147435   \n",
       "4      19.28828  19.11188  18.88937  18.80013  18.49183     QSO  2.011455   \n",
       "...         ...       ...       ...       ...       ...     ...       ...   \n",
       "49995  19.37295  18.12382  17.39886  16.98503  16.70585  GALAXY  0.113016   \n",
       "49996  18.52021  16.88262  16.03280  15.56884  15.22454  GALAXY  0.085063   \n",
       "49997  18.62718  17.30876  16.87371  16.62399  16.42296  GALAXY  0.054429   \n",
       "49998  19.55140  18.27711  17.62101  17.21947  17.03347  GALAXY  0.112571   \n",
       "49999  18.80772  17.75751  17.40500  17.21650  17.12295  GALAXY  0.043652   \n",
       "\n",
       "           zerr  \n",
       "0      0.000155  \n",
       "1      0.000028  \n",
       "2      0.000000  \n",
       "3      0.000009  \n",
       "4      0.000631  \n",
       "...         ...  \n",
       "49995  0.000011  \n",
       "49996  0.000014  \n",
       "49997  0.000008  \n",
       "49998  0.000009  \n",
       "49999  0.000007  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0895402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's scale them\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3ccbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9348161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='trained.keras'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "        \n",
    "    my_init = keras.initializers.glorot_uniform(seed=1)\n",
    "    model = keras.Sequential( [\n",
    "                # Input layer, do not change\n",
    "                tf.keras.layers.InputLayer(input_shape=np.shape(X_train[0])),\n",
    "                # Inner layers, can add/change\n",
    "                keras.layers.Dense(5,  activation='relu',kernel_initializer=my_init),\n",
    "                #keras.layers.Dense(16,  activation='tanh',kernel_initializer=my_init),\n",
    "                #keras.layers.Dense(8,  activation='tanh',kernel_initializer=my_init),\n",
    "                # Output layer, do not change\n",
    "                keras.layers.Dense(1, activation='sigmoid',kernel_initializer=my_init)])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "                if epoch < 10:\n",
    "                    return float(lr)\n",
    "                else:\n",
    "                    return float(lr * tf.math.exp(-0.05))\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=50, batch_size=10, validation_data=(X_test, y_test),\n",
    "                        callbacks = [\n",
    "                            # Drecrease learning rate\n",
    "                            tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "                            # Store the model with the best validation accuracy\n",
    "                            tf.keras.callbacks.ModelCheckpoint(\n",
    "                                filepath=filename,\n",
    "                                save_weights_only=False,\n",
    "                                monitor='val_accuracy',\n",
    "                                mode='max',\n",
    "                                save_best_only=True),\n",
    "                            # Save logfiles for tensorboard\n",
    "                            tf.keras.callbacks.TensorBoard(log_dir=\"logs\"+filename.split('.h5')[0], histogram_freq=1)],\n",
    "                        \n",
    "                        # Shuffle data at each epoch\n",
    "                        shuffle=True)\n",
    "\n",
    "    # Load the best model\n",
    "    model = keras.models.load_model(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a55837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities\n",
    "y_pred_prob = model.predict(X_test).ravel()  #(ravel flattens the array), can also use squeeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b4de2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")\n",
    "\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "465c3459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='teal', lw=2, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eeb4901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9826 - loss: 0.0774\n",
      "Classification score:  0.9839333295822144\n"
     ]
    }
   ],
   "source": [
    "# print the classification score:\n",
    "\n",
    "print('Classification score: ', model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f40254",
   "metadata": {},
   "source": [
    "## Let's now find the best hyperparameters for the network, cross validation with Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac282796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Define a function to create and compile the model\n",
    "def create_model(neurons, learning_rate):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=np.shape(X_train[0])),\n",
    "        keras.layers.Dense(neurons, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f6a9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'neurons': np.arange(5, 20, 5),\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    #'activation': ['relu', 'tanh']\n",
    "    #'batch_size': [16, 32, 64],\n",
    "    #'epochs': [10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "# all combinations of hyperparameters\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fb1c8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malvi/venv/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: (15, 0.01)\n",
      "Best accuracy: 0.9854666590690613\n"
     ]
    }
   ],
   "source": [
    "for params in param_combinations:\n",
    "    neurons, learning_rate = params\n",
    "\n",
    "    model = create_model(neurons, learning_rate)\n",
    "    \n",
    "    log_dir = f\"logs/hp_search_{neurons}_{learning_rate}\"\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=16,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fa75a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malvi/venv/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.1130 - val_accuracy: 0.9836 - val_loss: 0.0747\n",
      "Epoch 2/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0733 - val_accuracy: 0.9844 - val_loss: 0.0753\n",
      "Epoch 3/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0624 - val_accuracy: 0.9809 - val_loss: 0.0948\n",
      "Epoch 4/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0713 - val_accuracy: 0.9797 - val_loss: 0.1619\n",
      "Epoch 5/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0727 - val_accuracy: 0.9849 - val_loss: 0.0793\n",
      "Epoch 6/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0665 - val_accuracy: 0.9839 - val_loss: 0.0973\n",
      "Epoch 7/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0622 - val_accuracy: 0.9833 - val_loss: 0.0969\n",
      "Epoch 8/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0757 - val_accuracy: 0.9847 - val_loss: 0.0947\n",
      "Epoch 9/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0699 - val_accuracy: 0.9839 - val_loss: 0.0904\n",
      "Epoch 10/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0653 - val_accuracy: 0.9851 - val_loss: 0.0921\n",
      "Epoch 11/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0600 - val_accuracy: 0.9850 - val_loss: 0.0724\n",
      "Epoch 12/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0565 - val_accuracy: 0.9840 - val_loss: 0.1103\n",
      "Epoch 13/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0678 - val_accuracy: 0.9856 - val_loss: 0.0812\n",
      "Epoch 14/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0551 - val_accuracy: 0.9857 - val_loss: 0.0807\n",
      "Epoch 15/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0622 - val_accuracy: 0.9856 - val_loss: 0.0722\n",
      "Epoch 16/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0622 - val_accuracy: 0.9859 - val_loss: 0.0865\n",
      "Epoch 17/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0661 - val_accuracy: 0.9847 - val_loss: 0.0878\n",
      "Epoch 18/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0662 - val_accuracy: 0.9859 - val_loss: 0.0829\n",
      "Epoch 19/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0568 - val_accuracy: 0.9861 - val_loss: 0.0749\n",
      "Epoch 20/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0642 - val_accuracy: 0.9857 - val_loss: 0.0773\n",
      "Epoch 21/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0665 - val_accuracy: 0.9864 - val_loss: 0.0798\n",
      "Epoch 22/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0634 - val_accuracy: 0.9857 - val_loss: 0.0886\n",
      "Epoch 23/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0635 - val_accuracy: 0.9854 - val_loss: 0.0884\n",
      "Epoch 24/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0512 - val_accuracy: 0.9847 - val_loss: 0.1118\n",
      "Epoch 25/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0654 - val_accuracy: 0.9840 - val_loss: 0.0915\n",
      "Epoch 26/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0597 - val_accuracy: 0.9866 - val_loss: 0.0933\n",
      "Epoch 27/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0594 - val_accuracy: 0.9859 - val_loss: 0.0948\n",
      "Epoch 28/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0575 - val_accuracy: 0.9851 - val_loss: 0.0685\n",
      "Epoch 29/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0591 - val_accuracy: 0.9856 - val_loss: 0.0636\n",
      "Epoch 30/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0602 - val_accuracy: 0.9859 - val_loss: 0.0702\n",
      "Epoch 31/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0588 - val_accuracy: 0.9863 - val_loss: 0.0639\n",
      "Epoch 32/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0587 - val_accuracy: 0.9861 - val_loss: 0.0713\n",
      "Epoch 33/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0553 - val_accuracy: 0.9856 - val_loss: 0.0869\n",
      "Epoch 34/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0575 - val_accuracy: 0.9859 - val_loss: 0.0834\n",
      "Epoch 35/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0549 - val_accuracy: 0.9840 - val_loss: 0.0829\n",
      "Epoch 36/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0619 - val_accuracy: 0.9864 - val_loss: 0.0774\n",
      "Epoch 37/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0578 - val_accuracy: 0.9847 - val_loss: 0.0803\n",
      "Epoch 38/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0581 - val_accuracy: 0.9857 - val_loss: 0.0819\n",
      "Epoch 39/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0587 - val_accuracy: 0.9841 - val_loss: 0.0929\n",
      "Epoch 40/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0566 - val_accuracy: 0.9824 - val_loss: 0.1429\n",
      "Epoch 41/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0690 - val_accuracy: 0.9866 - val_loss: 0.0679\n",
      "Epoch 42/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0589 - val_accuracy: 0.9857 - val_loss: 0.0757\n",
      "Epoch 43/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0546 - val_accuracy: 0.9870 - val_loss: 0.0755\n",
      "Epoch 44/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0585 - val_accuracy: 0.9847 - val_loss: 0.0890\n",
      "Epoch 45/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0601 - val_accuracy: 0.9857 - val_loss: 0.0858\n",
      "Epoch 46/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0525 - val_accuracy: 0.9831 - val_loss: 0.1407\n",
      "Epoch 47/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0596 - val_accuracy: 0.9860 - val_loss: 0.0850\n",
      "Epoch 48/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0579 - val_accuracy: 0.9854 - val_loss: 0.0984\n",
      "Epoch 49/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0603 - val_accuracy: 0.9843 - val_loss: 0.1026\n",
      "Epoch 50/50\n",
      "\u001b[1m2800/2800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0617 - val_accuracy: 0.9859 - val_loss: 0.0938\n",
      "Final Model - Train Accuracy: 0.9858\n",
      "Final Model - Test Accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with best parameters\n",
    "neurons, learning_rate = best_params\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "final_model = create_model(neurons, learning_rate)\n",
    "\n",
    "final_log_dir = \"logs/final_model\"\n",
    "final_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=final_log_dir, histogram_freq=1)\n",
    "\n",
    "final_history = final_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[final_tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the final model\n",
    "train_loss, train_accuracy = final_model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_accuracy = final_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Final Model - Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Final Model - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "final_model.save('best_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2cf5c",
   "metadata": {},
   "source": [
    "## while with the RandomForest I got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9a2c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 1.0000\n",
      "Random Forest Test Accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_train_accuracy = rf.score(X_train, y_train)\n",
    "rf_test_accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Random Forest Train Accuracy: {rf_train_accuracy:.4f}\")\n",
    "print(f\"Random Forest Test Accuracy: {rf_test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
